{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libaries and initialising my network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "#from plotly.colors import n_colorsy\n",
    "import Deep_Neural_Network_Script\n",
    "import mpmath\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "npts = 1\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "poly_model = Deep_Neural_Network_Script.NeuralNetwork(\n",
    "    number_of_hidden_layers= 10, \n",
    "    number_of_auxillary_variable = 3,\n",
    "    number_of_phase_space_parameters = 3,\n",
    "    hidden_layer_size = 30,\n",
    "    output_layer_size = 1,\n",
    "    activation_function = \"GELU\",\n",
    "    batch_size = 500,\n",
    "    normalisation_coefficient = 120,\n",
    "    xavier_gain = 1.5\n",
    ") \n",
    "torch.set_printoptions(precision=20)\n",
    "\n",
    "normalisation_coefficient = poly_model.normalisation_coefficient\n",
    "\n",
    "saved_model = '1L_GELU_10layer_30hidden_branch1_run9.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do some sort of normalisation for the features from the kaggle set. \n",
    "def s_normalisation(input_nodes):\n",
    "    if poly_model.activation_function == 'newGELU':  #or 'GELU\n",
    "        return (input_nodes + 30)/27  #makes all in puts between 0 and 1\n",
    "    else:\n",
    "        return input_nodes/30# + 29.99)/27\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "#training tools\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(poly_model.parameters(), lr =0.01)#\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.99, patience = 60, verbose=True)# 0.75\n",
    "\n",
    "\n",
    "network_gradients_array_hidden = []\n",
    "network_gradients_array_input = []\n",
    "network_gradients_array_output = []\n",
    "network_gradients_array_hidden_std = []\n",
    "network_gradients_array_input_std = []\n",
    "network_gradients_array_output_std = []\n",
    "\n",
    "\n",
    "iterations = 1000 \n",
    "freq = 10\n",
    "npts_cycle = int(iterations/(freq))\n",
    "\n",
    "#validation_set_size = \n",
    "\n",
    "#arrays to store information from the training\n",
    "y_max_array = [] \n",
    "y_min_array = []\n",
    "y_mean_array = []\n",
    "y_std_array = []\n",
    "loss_array = np.zeros(int(freq))\n",
    "val_loss_array = np.zeros(int(freq))\n",
    "iteration_array = np.zeros(int(freq))\n",
    "lr_array = np.zeros(int(freq))\n",
    "\n",
    "#make these np.zero arrays and fix values to them to increase speed\n",
    "activation_value_array = [] #6 is because number of hidden layers + 2\n",
    "activation_value_array_std = [] #6 is because number of hidden layers + 2\n",
    "weight_array = []\n",
    "bias_array = []\n",
    "\n",
    "#training loop for regression using y_observed and y_predicted \n",
    "for epoch in range(iterations):\n",
    "\n",
    "    if epoch == 10 or epoch ==int(iterations)-1:\n",
    "        with torch.no_grad():\n",
    "            network_gradients_array_hidden.append(poly_model.weights_hidden_hidden.grad)\n",
    "            network_gradients_array_input.append(poly_model.weights_input_hidden.grad)\n",
    "            network_gradients_array_output.append(poly_model.weights_hidden_output.grad)\n",
    "\n",
    "   #zero gradients\n",
    "    optimizer.zero_grad()   \n",
    "      \n",
    "\n",
    "    y_observed = (\"result of match from Kaggle\") #from featurs off of Kaggle\n",
    "   \n",
    "    y_predicted = poly_model.forward(normalised(\"feature off two sets of fighter off Kaggle\")) #outputs from my network\n",
    "\n",
    "    \n",
    "    loss = loss_function(y_predicted, y_observed)\n",
    "    \n",
    "    loss.backward() #    #backward pass\n",
    "\n",
    "\n",
    "#    torch.nn.utils.clip_grad_norm_(poly_model.parameters(), max_norm= 5e-5)\n",
    "   # for name, param in poly_model.named_parameters():\n",
    "    #    if param.grad is not None:\n",
    "     #       print(f'Gradient of {name}:\\n{param.grad}')\n",
    "      #  else:\n",
    "       #     print(f'No gradient for {name}')\n",
    "\n",
    "    optimizer.step() #update parameters\n",
    "    \n",
    "    \n",
    "    #check backprop   \n",
    "   # print(f'Parameter: poly_model.weights_hidden_output, Gradient: {poly_model.weights_hidden_output.grad[93:97]}')\n",
    "    #print(f'Parameter: poly_model.weights_hidden_hidden, Gradient: {poly_model.weights_hidden_hidden.grad[:,97, 19:23]}')\n",
    "    #print(f'Parameter: poly_model.weights_input_hidden, Gradient: {poly_model.weights_input_hidden.grad[:, 1:4]}')\n",
    "   # print(f'Parameter: poly_model.bias_hidden, Gradient: {poly_model.bias_hidden.grad[0:3, 0:3]}')\n",
    "    #for name, param in poly_model.named_parameters():\n",
    "        #print(f'gradient: {param.grad.shape}')\n",
    "        #print(f'Parameter: {name}, Gradient: {param.grad[0][0:6]}')\n",
    "        #print(f'Parameter: {name}, Gradient: {param.grad[0][0:6]}')\n",
    "        #Parameter: weights_input_hidden, Gradient: torch.Size([6, 100])\n",
    "        #Parameter: weights_hidden_hidden, Gradient: torch.Size([2, 100, 100])\n",
    "        #Parameter: weights_hidden_output, Gradient: torch.Size([100, 1])\n",
    "        #Parameter: bias_hidden, Gradient: torch.Size([4, 100])#\n",
    "  \n",
    "    #validation set \n",
    "    poly_model.eval() #\n",
    "    with torch.no_grad():\n",
    "        y_observed_val = (\"result of match from Kaggle (validation set)\") #from featurs off of Kaggle\n",
    "   \n",
    "        y_predicted_val = poly_model.forward(normalised(\"feature off two sets of fighter off Kaggle (validation set)\")) #outputs from my network\n",
    "\n",
    "        val_loss = loss_function(y_observed_val, y_predicted_val).to(device)\n",
    "        #print(val_loss) \n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    \n",
    "    poly_model.train()\n",
    "   \n",
    "    \n",
    "    #figure out the collection rate for network performance params. \n",
    "\n",
    "    if (epoch + 1) % collection_rate == 0: #10000   \n",
    "        poly_model.eval()\n",
    "        with torch.no_grad():\n",
    "      #      print(f'network integrand: {outputs[0]}')\n",
    "       #     print(f'true integrand: {y}')\n",
    "            loss_array[i_indication] = loss\n",
    "            val_loss_array[i_indication] = val_loss\n",
    "            iteration_array[i_indication] = epoch + 1\n",
    "            lr_array[i_indication] = optimizer.param_groups[0]['lr']\n",
    "     \n",
    "        poly_model.train()\n",
    "   \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
